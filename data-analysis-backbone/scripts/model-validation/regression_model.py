# -*- coding: utf-8 -*-
"""regression_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VCq9YVffqiQKqU_l-4GxSCF-hENYdmqf

# Regression model validation
"""

import pandas as pd
import numpy as np
import os

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

from joblib import load
from joblib import dump

import seaborn as sns
import matplotlib.pyplot as plt

ROOT_PATH = "./"
TRAINED_MODEL = "model-training/trained-model/"
TRAIN_TEST_SPLIT = "model-training/train-test-split/"
DEPLOYED_MODEL = "deployed-model/"
PLOTS = "model-validation/plots/"

"""Three key regression evaluation metrics are calculated and displayed: Mean Squared Error (MSE), Coefficient of Determination (R²), and Mean Absolute Error (MAE). MSE measures the average squared difference between the observed and predicted values, indicating the model's accuracy, with a lower value being preferable. R², or the coefficient of determination, assesses the proportion of the variance in the dependent variable that is predictable from the independent variables, with a value close to 1 indicating a high explanatory power. MAE calculates the average magnitude of errors in a set of predictions, without considering their direction. Printing these metrics provides a comprehensive overview of the model's performance, combining error magnitude (MSE, MAE) and goodness of fit (R²)."""

model = load(os.path.join(ROOT_PATH, TRAINED_MODEL, 'model.joblib'))

X_train = pd.read_parquet(
    ROOT_PATH
    + TRAIN_TEST_SPLIT
    + "X_train.parquet"
)

X_test = pd.read_parquet(
    ROOT_PATH
    + TRAIN_TEST_SPLIT
    + "X_test.parquet"
)

Y_test = pd.read_parquet(
    ROOT_PATH
    + TRAIN_TEST_SPLIT
    + "Y_test.parquet"
)
y_test  = Y_test['GoldsteinScale']
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)

mse = mean_squared_error(y_test, y_pred)

r2 = r2_score(y_test, y_pred)

mae = mean_absolute_error(y_test, y_pred)

# print(f"Mean Squared Error (MSE): {mse}")
# print(f"Coefficient of determination (R²): {r2}")
# print(f"Mean Absolute Error (MAE): {mae}")

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([-10, 10], [-10, 10], 'k--', lw=2)
plt.xlabel('Actual Values')
plt.ylabel('Predictions')
plt.title('Actual Values vs. Predictions')
plt.savefig(os.path.join(ROOT_PATH, PLOTS, "valuesVSpredictions.png"))

residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals, alpha=0.5)
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predictions')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.savefig(os.path.join(ROOT_PATH, PLOTS, "residual_plot.png"))

plt.figure(figsize=(10, 6))
sns.histplot(residuals, kde=True)
plt.xlabel('Residuals')
plt.title('Histogram of Residuals')
plt.savefig(os.path.join(ROOT_PATH, PLOTS, "histogram_of_residuals.png"))

# plt.show()

coefficients = model.coef_
selected_columns = ['credit_card_usage', 'electricity_price', 'fish_and_seafood_price', 'fuel_price',
       'hotel_bookings_domestic', 'hotel_bookings_international', 'ibex_35',
       'meat_and_fish_price', 'meat_price']
selected_indices = [list(X_train.columns).index(column) for column in selected_columns]

feature_importance = pd.DataFrame({'Feature': X_train[selected_columns].columns, 'Coefficient': coefficients[selected_indices]})

feature_importance = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index)

plt.figure(figsize=(10, 6))
sns.barplot(x='Coefficient', y='Feature', data=feature_importance)
plt.title('Feature Importance in the Linear Regression Model')
plt.xlabel('Coefficient Magnitude')
plt.ylabel('Features')
plt.savefig(os.path.join(ROOT_PATH, PLOTS, "feature_importance.png"))
# plt.show()

dump(model, os.path.join(ROOT_PATH, DEPLOYED_MODEL, 'model.joblib'))